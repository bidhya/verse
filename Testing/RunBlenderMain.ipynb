{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ac6554-5750-4ac1-a035-0ee48c7bdba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constrained water and energy balance estimation \n",
    "# v4.2: adapted from v4.1 by treating SCF known, G estimated offline\n",
    "# v4.3: adapted from v4.2 & 3.3 to handle to batch processing on OSC\n",
    "# v4.4: adapted from v4.3 to update ipopt deprecation\n",
    "# v4.5: moving σWRFG based on SCF 7/2/20 JLD\n",
    "# v4.6: adding SDC to objective function: MD & JD: 9/28/20\n",
    "# v4.7: adding \"pseudo-valid prior\" to starting points. remove SDC. MD: 1/7/21\n",
    "# v4.8: tweak error parameters. MD & JD: 1/8/21\n",
    "# v4.9 prior valid added to objective function. daily G capped in constraints. more outputs written 10/5/21\n",
    "# v4.9.1 remove SWE from objective\n",
    "# v4.9.2 added air temp\n",
    "# v51 Converted to function but still uses textfile as input\n",
    "# v52 Prototyping to pass the array directly to function [and fixed tab to 4 spaces]\n",
    "# v53 To set tab to 4 spaces (by copying/pasting)\n",
    "# v54 combine 9 separate textfile output in one txt file (due to file count limitation on Discover)\n",
    "# v55 Fixing error due to missing days of data due to Polar nights\n",
    "# v58 New updates by jack (Nov 2023)\n",
    "# Jan 29, 2024: Due to error on obj function σWRFG becoming zero, fixed the minimum σWRFG to 25 \n",
    "# Jun 21, 2024: No change for 1km run here. MODIS with UINT8 did not work likely because of missing due to no-data background and polar nights.\n",
    "\n",
    "using NCDatasets\n",
    "using Random\n",
    "using JuMP\n",
    "using Ipopt\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "Random.seed!(1234)  # seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5eace3-b5f5-440c-a3d2-2565d1a9a04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checkDirectoryExists (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function checkDirectoryExists(dir_path::String)\n",
    "    if !isdir(dir_path)\n",
    "        println(\"Directory does not exist. Creating: $dir_path\")\n",
    "        mkpath(dir_path)  # creates the directory and any necessary parent directories\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfa3c5a-4dad-4cbe-9c66-ec79781831c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "detPrecipScalar (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function blender(i,j,SWEprior, Pprior, Gprior, SCFinst, AirT, logDir, exp_dir, mu, sigma, twindow=2)\n",
    "function blender(i,j,SWEprior, Pprior, Gprior, SCFinst, AirT, logDir, exp_dir, psVal, twindow=2)\n",
    "  \"\"\"\n",
    "  inputs\n",
    "  ==============\n",
    "  i,j are pixel locations\n",
    "  SWEprior, Pprior, Gprior are prior estimates of SWE [m], Precipitation [m] and surface heat flux [W/m2]\n",
    "  SCFinst is measured snow covered fraction\n",
    "  AirT is air temperature [K]\n",
    "  logdir and exp_dir are directories where log and data are written\n",
    "    \n",
    "  variable sizes\n",
    "  =============== \n",
    "  SWE and SCF are storage terms, so will be length nt. \n",
    "  P, Melt, and G are flux terms, so will be length nt-1\n",
    "  for input, all variables are length nt, so just use Pprior[1:nt-1]. Note, Gprior currently unused\n",
    "  for output in section 4, will output fluxes as nt, with the last element set to 0.    \n",
    "\n",
    "  \"\"\"\n",
    "    # 0 handle variable sizes\n",
    "    nt = length(SCFinst)\n",
    "    Pprior = Pprior[1:nt-1]\n",
    "    # println(\"Inside Estimate_v61...\")\n",
    "    # println(SCFinst)\n",
    "\n",
    "    # # 1a Fill in missing SCF [Feb 23, 2023]\n",
    "    # for i=1:nt\n",
    "    #     if ismissing(SCFinst[i])\n",
    "    #         # make it a function of SWEprior\n",
    "    #         SCFinst[i]=1  # June 20, 2024: cannot convert a value to missing for assignment. When using uint8 based data.\n",
    "    #     end\n",
    "    # end\n",
    "    #log_filePS =  \"$logDir/Pix_$(i)_$(j)_PS.txt\"  # original\n",
    "    # 1 Smooth SCF observations    \n",
    "    # twindow = 5\n",
    "    SCFobs = smoothdata(SCFinst, twindow, nt, \"median\")\n",
    "    # SCFobs = fix_modis(SCFinst)  # apply MODIS fix developed by Jack (Feb 04, 2025)\n",
    "    # twindow = 60\n",
    "    SCF_smooth_season = smoothdata(SCFobs, 30, nt, \"mean\")  # before it was 60\n",
    "\n",
    "    # 1.1 Calculate precipitation scalar\n",
    "    #precipScalar = detPrecipScalar(SCFobs, mu, sigma, gamma,yMin,yMax,log_filePS)\n",
    "    \n",
    "    #Pprior = precipScalar.*Pprior;\n",
    "    #SWEprior = precipScalar.*SWEprior;\n",
    "    Pprior = psVal.*Pprior;\n",
    "    SWEprior = psVal.*SWEprior;\n",
    "    # 2 Define hyperparameters\n",
    "    tmelt,tmelt_smooth,SWEmax,SWEmin_global,Meltmax,σP,σSWE,k,Melt0,L=define_hyperparameters(SCF_smooth_season, nt, Pprior, SWEprior, AirT, SCFobs)\n",
    "\n",
    "    # 3 Solve\n",
    "    m = Model(optimizer_with_attributes(Ipopt.Optimizer,\"max_iter\"=>5000))\n",
    "    # set_silent(m)\n",
    "    # define variables and bounds\n",
    "    @variable(m, SWEmin_global <= SWE[i=1:nt] <= SWEmax[i], start=SWEprior[i])\n",
    "    @variable(m, Precip[i=1:nt-1]>=0. ,start=Pprior[i]);\n",
    "    @variable(m, 0. <= Melt[i=1:nt-1]<= Meltmax)\n",
    "    @variable(m, Mcost[i=1:nt-1] >=0)\n",
    "    # define constraints\n",
    "    for i in 1:nt-1\n",
    "      @NLconstraint(m,Mcost[i]==L/(1+exp( -k*(Melt[i]-Melt0))))\n",
    "    end\n",
    "    for i in 1:nt-1\n",
    "      @constraint(m,SWE[i+1]==SWE[i]+Precip[i]-Melt[i])\n",
    "    end\n",
    "    # define objective function\n",
    "    @objective(m,Min,sum((Precip-Pprior).^2 ./σP.^2) + sum((SWE-SWEprior ).^2 ./ σSWE.^2) + sum(Mcost.^2))\n",
    "    log_file =  \"$logDir/Pix_$(i)_$(j)_$(twindow).txt\"  # original\n",
    "\n",
    "    \n",
    "    # solve\n",
    "    redirect_stdio(stdout=log_file, stderr=log_file) do\n",
    "      optimize!(m)\n",
    "    end\n",
    "    # print(termination_status(m))\n",
    "    \n",
    "    # 4 extract\n",
    "    NODATAvalue = -9999\n",
    "    SWEhat=JuMP.value.(SWE)\n",
    "    Phat=zeros(nt,1)\n",
    "    Phat[1:nt-1] = JuMP.value.(Precip)\n",
    "    Melt_hat = zeros(nt,1)\n",
    "    Melt_hat[1:nt-1] = JuMP.value.(Melt);\n",
    "    \n",
    "    Δt = 86400; #s/day\n",
    "    ρw = 1000; #density of water\n",
    "    Lf = 0.334E6; #Latent heat of fusion J/kg    \n",
    "    GmeltHat = Melt_hat/Δt*Lf*ρw\n",
    "    \n",
    "    Ghat = ones(nt,1)*NODATAvalue\n",
    "    Ushat = ones(nt,1)*NODATAvalue\n",
    "    G_pv = ones(nt,1)*NODATAvalue\n",
    "    U_pv = ones(nt,1)*NODATAvalue\n",
    "    Gmelt_pv = ones(nt,1)*NODATAvalue\n",
    "    SWEpv = ones(nt,1)*NODATAvalue\n",
    "    Pprint = ones(nt,1); Pprint[1:nt-1] = Pprior;\n",
    "    \n",
    "    # 5 output\n",
    "    out_vars = hcat(SWEhat, GmeltHat, Ghat, Phat, Pprint, Ushat, G_pv, Gmelt_pv, U_pv, SWEprior, SCFobs)\n",
    "    writedlm(\"$(exp_dir)/Pix_$(i)_$(j)_$(twindow).txt\", out_vars)\n",
    "    \n",
    "    # 6 clean up\n",
    "    m = nothing\n",
    "    GC.gc()\n",
    "    return nothing    \n",
    "end\n",
    "\n",
    "# function smoothdata(SCFinst,twindow,nt,smoothfunc)\n",
    "#     # println(\"Inside smoothdata function: $twindow, $nt, $smoothfunc\")\n",
    "#     SCF_smooth=zeros(nt,1)\n",
    "#     for i=1:nt\n",
    "#         istart = trunc(Int,i-round(twindow/2))\n",
    "#         iend = trunc(Int,i+round(twindow/2))        \n",
    "#         # if i < twindow || i > nt-twindow\n",
    "#         if istart < 1 || iend > nt\n",
    "#             SCF_smooth[i]=0  # BY?: why not keep whatever the original value was. Moreover, this is already initialized to 0 at the beginning.\n",
    "#         else            \n",
    "#             if smoothfunc == \"mean\"\n",
    "#                 SCF_smooth[i] = mean(SCFinst[istart:iend])\n",
    "#             elseif smoothfunc==\"median\"\n",
    "#                 SCF_smooth[i] = median(SCFinst[istart:iend])\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "    \n",
    "#     return SCF_smooth\n",
    "# end\n",
    "\n",
    "\n",
    "function smoothdata(SCFinst, twindow, nt, smoothfunc)\n",
    "    \"\"\"\n",
    "    Smooth data using a moving average or median filter.\n",
    "    Parameters:\n",
    "    ============\n",
    "    SCFinst: Input data to be smoothed.\n",
    "    twindow: Window size for smoothing.\n",
    "        example: 1 means smooth using 1 data point on either side of the current point.\n",
    "        In this formulation, use half the value that was originally used by Mike (ie, 60 is now 30 etc.).\n",
    "    nt: Length of the input data.\n",
    "    smoothfunc: Type of smoothing function ('mean' or 'median').\n",
    "\n",
    "    \"\"\"\n",
    "    # println(\"Inside Smoothing data...\")\n",
    "    # println(\"$twindow, $nt, $smoothfunc\")\n",
    "    # better to copy \"SCFinst\" so the smooth function doesn't modify the original data. Even better apppend border on both sides of the data.\n",
    "    SCF_smooth=zeros(nt,1)\n",
    "    for i=(1+twindow):(nt-twindow)\n",
    "        # adding 1 (ie, 1+twindow) in the for loop because Julia is 1-based indexing\n",
    "        if smoothfunc == \"mean\"\n",
    "            SCF_smooth[i] = mean(SCFinst[i-twindow:i+twindow])\n",
    "            # SCF_smooth[i] = mean(skipmissing(SCFinst[i-twindow:i+twindow]))  # use this when there is missing data\n",
    "        elseif smoothfunc==\"median\"\n",
    "            SCF_smooth[i] = mean(SCFinst[i-twindow:i+twindow])\n",
    "            # SCF_smooth[i] = mean(skipmissing(SCFinst[i-twindow:i+twindow]))  # use this when there is missing data\n",
    "        end\n",
    "    end    \n",
    "    return SCF_smooth\n",
    "end\n",
    "\n",
    "function define_uncertainty(Pprior, SWEprior, AirT, SCFobs, nt, tmelt_smooth)\n",
    "    # convert air temperature K-> C\n",
    "    AirT = AirT.-273.15\n",
    "    \n",
    "    # 2.2.1 Precipitation Uncertainty\n",
    "    RelPUnc = 0.3; #[-] this applies to cumulative precipitation\n",
    "    # Uncertainty for accumulation . precip is size nt-1\n",
    "    σP = zeros(nt-1,1)\n",
    "    σPmin = 0.001\n",
    "    Pthresh = 0.001\n",
    "    for i=1:nt-1\n",
    "      if Pprior[i]<Pthresh\n",
    "        σP[i]=σPmin\n",
    "      else\n",
    "        σP[i]=Pprior[i]*RelPUnc\n",
    "      end\n",
    "    end    \n",
    "    # adjust uncertainty to apply to the number of snow days\n",
    "    nsnowday = 0\n",
    "    Tprecip_thresh = 1.5\n",
    "    for i=1:nt-1\n",
    "        if Pprior[i]>Pthresh && AirT[i] < Tprecip_thresh\n",
    "            nsnowday += 1\n",
    "        end\n",
    "    end\n",
    "    if nsnowday > 0\n",
    "        σP = σP*sqrt(nsnowday);    \n",
    "    end\n",
    "    \n",
    "    # 2.2.2 SWE Uncertainty\n",
    "    fSWE = 0.4\n",
    "    σSWE = SWEprior*fSWE;\n",
    "    σSWEmin = 0.01\n",
    "    σSWEmax = 10\n",
    "    for i=1:nt\n",
    "        # if SWEprior[i]>0 && SCFobs[i]==0\n",
    "        if SCFobs[i]==0 || tmelt_smooth[i]>.1    \n",
    "            σSWE[i] = σSWEmax\n",
    "        end\n",
    "        if σSWE[i] < σSWEmin\n",
    "            σSWE[i] = σSWEmin\n",
    "        end\n",
    "    end   \n",
    "    \n",
    "    return σP, σSWE\n",
    "end\n",
    "\n",
    "function define_hyperparameters(SCF_smooth_season,nt,Pprior,SWEprior,AirT, SCFobs)\n",
    "    \"\"\"\n",
    "    list of hyperparameters\n",
    "    =======================\n",
    "    twindow for smoothing SCF for snow on/off constraint - defined in main\n",
    "    twindow for smoothing SCF for identifying melt times - defined in main\n",
    "    ΔSCFthresh\n",
    "    twindow for smoothing melt times\n",
    "    SWEmax_global\n",
    "    SWEmin_global\n",
    "    Meltmax    \n",
    "    k,Melt0,L\n",
    "    σPmin - defined in define_uncertainty\n",
    "    Pthresh -  defined in define_uncertainty\n",
    "    Tprecip_thresh -  defined in define_uncertainty\n",
    "    fSWE -  defined in define_uncertainty\n",
    "    σSWEmin -  defined in define_uncertainty\n",
    "    σSWEmax -  defined in define_uncertainty        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # 2.1 Define prior estimates\n",
    "    # 2.1.1 Define times when snow is melting \n",
    "    tmelt = zeros(nt,1)\n",
    "    ΔSCFthresh = -0.01\n",
    "    for i=2:nt\n",
    "        if SCF_smooth_season[i] - SCF_smooth_season[i-1] < ΔSCFthresh\n",
    "            tmelt[i] = 1\n",
    "        end\n",
    "    end    \n",
    "    # twindow = 30\n",
    "    tmelt_smooth = smoothdata(tmelt, 15, nt, \"mean\")  # before it was 30\n",
    "    \n",
    "    # 2.2 Extreme / limit values\n",
    "    # 2.2.1 SWE\n",
    "    SWEmax_global = 5\n",
    "    SWEmin_global = 1.0e-6 #1/1000 mm TODO (BNY) we can use this for missing values due flags such as to water etc. ie, give those pixels a zero value\n",
    "    # define SWEmax as a function of time and of SCF\n",
    "    #    set SWEmax to 0 if SCF is low\n",
    "    SWEmax = zeros(nt,1)\n",
    "    for i = 1:nt\n",
    "      if SCFobs[i] == 0\n",
    "        SWEmax[i] = SWEmin_global\n",
    "      else\n",
    "        SWEmax[i] = SWEmax_global\n",
    "      end\n",
    "    end    \n",
    "    #2.2.2 Melt\n",
    "    Meltmax = 0.075;\n",
    "    \n",
    "    # 2.3 Define uncertainty\n",
    "    σP,σSWE = define_uncertainty(Pprior, SWEprior, AirT, SCFobs, nt, tmelt_smooth)\n",
    "    # 2.4 Melt cost function parameters\n",
    "    k = 500\n",
    "    Melt0 = 0.05\n",
    "    L = 1\n",
    "    \n",
    "    return tmelt, tmelt_smooth, SWEmax, SWEmin_global, Meltmax, σP, σSWE, k, Melt0, L\n",
    "end\n",
    "\n",
    "function fix_modis(SCF)\n",
    "    \"\"\" This function is used to fix the MODIS snow cover fraction (SCF) data is designed by Jack Dechow.\n",
    "        It corrects the SCF data by adjusting values based on the differences between consecutive days.\n",
    "        The function iterates through the SCF data, calculates the differences, and applies corrections based on specific thresholds.\n",
    "        The function also includes a mechanism to find the final day of snow off and adjust the SCF value accordingly.\n",
    "        The function is designed to handle edge cases and ensure that the final SCF value is reasonable.            \n",
    "    \"\"\"\n",
    "  # Define length of array (365)\n",
    "  nt = length(SCF)\n",
    "\n",
    "  # %% 1.1 Calculate deltaSCF\n",
    "  # We calculate the value ΔSCF which is defined as\n",
    "  # Σ[ abs[SCF(i)-SCF(i+1)] + abs[SCF(i+1)-SCF(i+2)] ]\n",
    "  # Depending on value of ΔSCF we do one of three things\n",
    "  \n",
    "  for i in 150:nt-2  # Python uses 0-based indexing, so 150 in MATLAB is 149 in Python\n",
    "      deltaSCF = abs(SCF[i] - SCF[i+1]) + abs(SCF[i+1] - SCF[i+2])\n",
    "      # print(deltaSCF)\n",
    "      if deltaSCF == 2  # If ΔSCF == 2, that means the SCF went from 1→0→1 which is bad\n",
    "          tmp = SCF[i:i+2]  #.copy()\n",
    "          tmp[tmp .== 0] .= 0.667  # In this case we find the 0 SCF day (which should be in the middle) and then we set that days SCF = 0.667\n",
    "          SCF[i:i+2] = tmp\n",
    "          # println(2)\n",
    "      elseif deltaSCF > 1.5  # Elif ΔSCF > 1.5, we set any 0 SCF day to 1/3 of value Σ[abs(ΔSCF(i:1+2))]\n",
    "          tmp = SCF[i:i+2]  #.copy()\n",
    "          tmp[tmp .== 0] .= deltaSCF/3\n",
    "          SCF[i:i+2] = tmp\n",
    "          println(1.5)\n",
    "      elseif deltaSCF > 0.9  # Elif ΔSCF > 0.9, we set any 0 SCF day to 1/2 of value Σ[abs(ΔSCF(i:1+2))]\n",
    "          tmp = SCF[i:i+2] #.copy()\n",
    "          tmp[tmp .== 0] .= deltaSCF/2\n",
    "          SCF[i:i+2] = tmp\n",
    "          # print(0.9)\n",
    "      end\n",
    "  end\n",
    "  # %% 1.2 Find final day of snow off\n",
    "  # After the loop above finishes, find the final day of snow off\n",
    "  # extra to check for \n",
    "  stopIdx = 0\n",
    "  for i in 150:nt\n",
    "      if SCF[i] == 0  # Find a day with zero SCF\n",
    "          global stopIdx = i  # Set counter value to whatever idx i is\n",
    "          numSCF = sum(SCF[i:nt])  # Sum all remaining SCF values\n",
    "          if numSCF == 0  # If there is no more SCF for the rest of the year, break\n",
    "              break\n",
    "          end\n",
    "      end\n",
    "  end\n",
    "  # Add a single step down day to the SCF timeseries\n",
    "  # This ensures if the last day of SCF is above 50% snow cover\n",
    "  # We add a single extra day to the timeseries where we cut that value down\n",
    "  # by 50% to add an easier downramp for the melt timeseries\n",
    "  # use try/catch to avoid error if stopIdx was not assigned above\n",
    "  if stopIdx > 1 && SCF[stopIdx-1] > 0.49  # error if stopIdx was not assigned above; hence, wrapping in try block\n",
    "      SCF[stopIdx] = 0.5 * SCF[stopIdx-1]\n",
    "  end\n",
    "  return SCF\n",
    "end\n",
    "\n",
    "function detPrecipScalar(SCFinst, mu, sigma, gamma,yMin,yMax,logfile)\n",
    "    \"\"\"\n",
    "    Calculate precip scaling values based on logistic function (tanh)\n",
    "    Logistic funciton f(x) has output (y) values between [yMin yMax]\n",
    "    Center of function i.e. inflection point at basinMu\n",
    "    Parameters:\n",
    "    ============\n",
    "    SCFinst: Pixel SCF timeseries -> used to calculate annual average SCF (avgSCF)\n",
    "    mu: Mean of avgSCF for all pix in basin; Also the inflection point i.e. center point of tanh();\n",
    "        MUST BE NONNEGATIVE\n",
    "    sigma : Standard deviation of avgSCF for all pix in basin\n",
    "    gamma: Steepness parameter for logistic function, calculated separate in detGamma function\n",
    "    yMin: Minimum output value of logistic function;\n",
    "        MUST BE NONNEGATIVE\n",
    "    yMax: Maximum output value of logistic function; \n",
    "        MUST BE GREATER THAN yMIN\n",
    "    =============\n",
    "    \"\"\"\n",
    "   \n",
    "    # Throw errors for bad inputs\n",
    "    if yMin < 0 || mu < 0\n",
    "        throw(DomainError((x, y), \"Error! Inputs yMin and basinMu must be non-negative!\"))\n",
    "    end\n",
    "\n",
    "    if yMin > yMax\n",
    "        throw(DomainError((x, y), \"Error! Input yMax must be greater than yMin!\"))\n",
    "    end\n",
    "    \n",
    "    avgSCF = mean(SCFinst) # Average of SCFinst over entire water year for current pixel\n",
    "    # Logistic function\n",
    "    y_norm = 0.5 * (tanh(gamma * (avgSCF - mu)) + 1);\n",
    "    y = y_norm * (yMax - yMin) + yMin;\n",
    "\n",
    "        msg = \" Precipitation Scalar Record; PSval = $y\\n\"\n",
    "        write(logfile, msg)\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab260ae-3c4b-43db-bfdc-7a6d1f7bfeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "callBlenderWatershed (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function callBlenderWatershed(domainName, WY, vN, scaleFlag)\n",
    "    \"\"\"\n",
    "        This function will call and run the most recent version of Blender over a single\n",
    "        four test domains (TLM | OLY | CRB | CJR). This version only runs for WY15 and WY16. \n",
    "        The following version codes vN are accepted:\n",
    "    \n",
    "            v0: Run current Blender over single watershed\n",
    "            v1: Deprecated, same output as v0\n",
    "            v2: Run Blender with precipitation scaling processing\n",
    "            v3: Run Blender with precipitation scaling process; LIS inputs smoothed with gaussian filtering\n",
    "    \n",
    "        Scale flag = 0  |  1\n",
    "\n",
    "        ## JLD 5/13/25\n",
    "        \"\"\"\n",
    "    ## Assign directories\n",
    "    DataDir = (\"/Users/jldechow/Documents/Projects/UNC/CoReSSD/Runs/Data/\" * WY * \"/\" * vN * \"/\" * domainName * \"_\" * WY * \"_\" * vN * \".nc\")\n",
    "    ScaleDir = (\"/Users/jldechow/Documents/Projects/UNC/CoReSSD/Runs/Data/\" * WY * \"/\" * vN * \"/\" * domainName * \"_PrecipScalar_\" * WY * \".nc\")\n",
    "    exp_dir = (\"/Users/jldechow/Documents/Projects/UNC/CoReSSD/Runs/Out/\" * vN * \"/\" * WY * \"/\" * domainName)\n",
    "    logDir =  (\"/Users/jldechow/Documents/Projects/UNC/CoReSSD/Runs/Logs/\"  * vN * \"/\" * WY * \"/\" * domainName)\n",
    "\n",
    "    ## Double log and out directories exist, script fails if they don't.\n",
    "    checkDirectoryExists(exp_dir)\n",
    "    checkDirectoryExists(logDir)\n",
    "    \n",
    "    ## Read in Blender input data\n",
    "    ds = Dataset(DataDir, \"r\")\n",
    "    # List all variable names (optional, for inspection)\n",
    "    varnames = collect(keys(ds))\n",
    "    # Var Names manually set\n",
    "    varnames = [\"SWE\", \"Precip\", \"AirT\", \"SCF\", \"G\"]\n",
    "    # Read each variable into memory (this keeps things fast in the loop)\n",
    "    data = Dict(name => ds[name][:] for name in varnames)\n",
    "    ## Make Structure and throw into different var type\n",
    "    # Due to Julia syntax rules, this section has to be defined outside the function before it is called. Here I am laying the\n",
    "    # framework for it, but I will actually define this struct outside the function in a loop when I call it.\n",
    "    # struct NCData\n",
    "    #     SWE::Array{Float32,3}\n",
    "    #     Precip::Array{Float32,3}\n",
    "    #     AirT::Array{Float32,3}\n",
    "    #     SCF::Array{Float32,3}\n",
    "    #     G::Array{Float32,3}\n",
    "    # end\n",
    "    ncdata = NCData(\n",
    "        data[\"SWE\"],\n",
    "        data[\"Precip\"],\n",
    "        data[\"AirT\"],\n",
    "        data[\"SCF\"],\n",
    "        data[\"G\"]\n",
    "    )\n",
    "    \n",
    "    ## Get size of one of the vars for loop\n",
    "    nx, ny, nt = size(ncdata.SWE) \n",
    "\n",
    "    # Read in scaling data if required - otherwise fill with array of ones\n",
    "    if scaleFlag == 1\n",
    "        ds2 = Dataset(ScaleDir,\"r\")  # open in read-only mode\n",
    "        PrecipScalar = ds2[\"PrecipScalar\"][:]          # read the full 2D array\n",
    "        close(ds2) \n",
    "    else\n",
    "        PrecipScalar = ones(int,nx, ny)\n",
    "    end\n",
    "\n",
    "    for i in 1:nx\n",
    "        for j in 1:ny\n",
    "            ts_var1 = ncdata.SWE[i, j, :]./1000\n",
    "            ts_var2 = ncdata.Precip[i, j, :]./1000\n",
    "            ts_var3 = ncdata.AirT[i, j, :]./100\n",
    "            ts_var4 = ncdata.SCF[i, j, :]\n",
    "            ts_var5 = ncdata.G[i, j, :]\n",
    "\n",
    "            ts_var6 = PrecipScalar[i,j]\n",
    "\n",
    "            # Convert from 1×1×365 SubArray to 365-element Vector aka MATLAB squeeze function\n",
    "            v1 = vec(ts_var1)\n",
    "            v2 = vec(ts_var2)\n",
    "            v3 = vec(ts_var3)\n",
    "            v4 = vec(ts_var4)\n",
    "            v5 = vec(ts_var5)\n",
    "            v6 = ts_var6\n",
    "\n",
    "            #Skip if any of 5 variables are entirely NaN at this (i, j)\n",
    "            if all(isnan.(v1)) || all(isnan.(v2)) || all(isnan.(v3)) ||\n",
    "               all(isnan.(v4)) || all(isnan.(v5)) || isnan.(v6)\n",
    "                continue  # Skip this pixel\n",
    "            else\n",
    "            # Call Blender on the 1D time series\n",
    "            blender(i,j,v1, v2, v3, v4, v5,logDir, exp_dir, v6)\n",
    "        \n",
    "            end\n",
    "\n",
    "        # Do something with result...\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496692e8-d358-4c1c-b959-1d119ef433a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "domainName = \"CCA\";\n",
    "WY = \"WY15\"\n",
    "vN = \"V3\"\n",
    "scaleFlag = 1;\n",
    "\n",
    "\n",
    "struct NCData\n",
    "    SWE::Array{Float32,3}\n",
    "    Precip::Array{Float32,3}\n",
    "    AirT::Array{Float32,3}\n",
    "    SCF::Array{Float32,3}\n",
    "    G::Array{Float32,3}\n",
    "end\n",
    "\n",
    "callBlenderWatershed(domainName, WY, vN, scaleFlag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9308bb8-cabb-4d21-8065-c3b3386762d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
